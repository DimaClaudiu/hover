{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hover - API Documentation This site hosts the more technical details and considerations of the Hover package. For feature demonstrations and quick examples, check out the project homepage .","title":"Home"},{"location":"#hover-api-documentation","text":"This site hosts the more technical details and considerations of the Hover package. For feature demonstrations and quick examples, check out the project homepage .","title":"Hover - API Documentation"},{"location":"reference/core-dataset/","text":"hover.core.dataset.SupervisableDataset Type-agnostic class for a dataset open to supervision. Raw -- piecewise annoatation -> Gold -> Dev/Test Raw -- batch annotation -> Noisy -> Train Keeping a DataFrame form and a list-of-dicts form, with the intention that synchronization should be called manually and sparingly. __init__ ( self , raw_dictl , train_dictl = None , dev_dictl = None , test_dictl = None , feature_key = 'feature' , label_key = 'label' ) special Initialize the dataset with dictl and df forms; initialize the mapping between categorical-int and string labels. param raw_dictl: a list of dicts holding the raw data that DO NOT have annotation. param train_dictl: a list of dicts holding the batch-annotated noisy train set. param dev_dictl: a list of dicts holding the gold dev set. param test_dictl: a list of dicts holding the gold test set. param feature_key: key in each piece of dict mapping to the feature. param label_key: key in each piece of dict mapping to the ground truth in STRING form. Source code in hover/core/dataset.py def __init__ ( self , raw_dictl , train_dictl = None , dev_dictl = None , test_dictl = None , feature_key = \"feature\" , label_key = \"label\" , ): \"\"\" Initialize the dataset with dictl and df forms; initialize the mapping between categorical-int and string labels. - param raw_dictl: a list of dicts holding the raw data that DO NOT have annotation. - param train_dictl: a list of dicts holding the batch-annotated noisy train set. - param dev_dictl: a list of dicts holding the gold dev set. - param test_dictl: a list of dicts holding the gold test set. - param feature_key: key in each piece of dict mapping to the feature. - param label_key: key in each piece of dict mapping to the ground truth in STRING form. \"\"\" def dictl_transform ( dictl , labels = True ): \"\"\" Burner function to transform the input list of dictionaries into standard format. \"\"\" # transform the feature and possibly the label key_transform = { feature_key : self . __class__ . FEATURE_KEY } if labels : key_transform [ label_key ] = \"label\" # corner case when dictl is empty or None if not dictl : return [] return [ { key_transform . get ( _key , _key ): _value for _key , _value in _dict . items () } for _dict in dictl ] self . dictls = { \"raw\" : dictl_transform ( raw_dictl , labels = False ), \"train\" : dictl_transform ( train_dictl ), \"dev\" : dictl_transform ( dev_dictl ), \"test\" : dictl_transform ( test_dictl ), } self . synchronize_dictl_to_df () self . df_deduplicate () self . synchronize_df_to_dictl () self . setup_label_coding () compute_2d_embedding ( self , vectorizer , method , ** kwargs ) Get embeddings in the xy-plane and return the reducer. Source code in hover/core/dataset.py def compute_2d_embedding ( self , vectorizer , method , ** kwargs ): \"\"\" Get embeddings in the xy-plane and return the reducer. \"\"\" from hover.core.representation.reduction import DimensionalityReducer # prepare input vectors to manifold learning subset = [ \"raw\" , \"train\" , \"dev\" ] fit_inp = [] for _key in subset : _df = self . dfs [ _key ] if _df . empty : continue fit_inp += _df [ self . __class__ . FEATURE_KEY ] . tolist () fit_arr = np . array ([ vectorizer ( _inp ) for _inp in tqdm ( fit_inp )]) # initialize and fit manifold learning reducer reducer = DimensionalityReducer ( fit_arr ) embedding = reducer . fit_transform ( method , ** kwargs ) # assign x and y coordinates to dataset start_idx = 0 for _key in subset : _df = self . dfs [ _key ] _length = _df . shape [ 0 ] _df [ \"x\" ] = pd . Series ( embedding [ start_idx : ( start_idx + _length ), 0 ]) _df [ \"y\" ] = pd . Series ( embedding [ start_idx : ( start_idx + _length ), 1 ]) start_idx += _length return reducer loader ( self , key , vectorizer , batch_size = 64 , smoothing_coeff = 0.0 ) Prepare a Torch Dataloader for training or evaluation. param key(str): the subset of dataset to use. param vectorizer(callable): callable that turns a string into a vector. param smoothing_coeff: the smoothing coeffient for soft labels. type smoothing_coeff: float Source code in hover/core/dataset.py def loader ( self , key , vectorizer , batch_size = 64 , smoothing_coeff = 0.0 ): \"\"\" Prepare a Torch Dataloader for training or evaluation. - param key(str): the subset of dataset to use. - param vectorizer(callable): callable that turns a string into a vector. - param smoothing_coeff: the smoothing coeffient for soft labels. - type smoothing_coeff: float \"\"\" # take the slice that has a meaningful label df = self . dfs [ key ][ self . dfs [ key ][ \"label\" ] != module_config . ABSTAIN_DECODED ] labels = df [ \"label\" ] . apply ( lambda x : self . label_encoder [ x ]) . tolist () features = df [ self . __class__ . FEATURE_KEY ] . tolist () output_vectors = one_hot ( labels , num_classes = len ( self . classes )) console . print ( f \"Preparing { key } input vectors...\" , style = \"blue\" ) input_vectors = [ vectorizer ( _f ) for _f in tqdm ( features )] if smoothing_coeff > 0.0 : output_vectors = label_smoothing ( output_vectors , coefficient = smoothing_coeff ) console . print ( f \"Preparing { key } data loader...\" , style = \"blue\" ) loader = vector_dataloader ( input_vectors , output_vectors , batch_size = batch_size ) console . print ( f \"Prepared { key } loader consisting of { len ( features ) } examples with batch size { batch_size } \" , style = \"green\" , ) return loader hover.core.dataset.SupervisableTextDataset Can add text-specific methods.","title":"hover.core.dataset"},{"location":"reference/core-dataset/#hovercoredatasetsupervisabledataset","text":"","title":"hover.core.dataset.SupervisableDataset"},{"location":"reference/core-dataset/#hover.core.dataset.SupervisableDataset","text":"Type-agnostic class for a dataset open to supervision. Raw -- piecewise annoatation -> Gold -> Dev/Test Raw -- batch annotation -> Noisy -> Train Keeping a DataFrame form and a list-of-dicts form, with the intention that synchronization should be called manually and sparingly.","title":"hover.core.dataset.SupervisableDataset"},{"location":"reference/core-dataset/#hover.core.dataset.SupervisableDataset.__init__","text":"Initialize the dataset with dictl and df forms; initialize the mapping between categorical-int and string labels. param raw_dictl: a list of dicts holding the raw data that DO NOT have annotation. param train_dictl: a list of dicts holding the batch-annotated noisy train set. param dev_dictl: a list of dicts holding the gold dev set. param test_dictl: a list of dicts holding the gold test set. param feature_key: key in each piece of dict mapping to the feature. param label_key: key in each piece of dict mapping to the ground truth in STRING form. Source code in hover/core/dataset.py def __init__ ( self , raw_dictl , train_dictl = None , dev_dictl = None , test_dictl = None , feature_key = \"feature\" , label_key = \"label\" , ): \"\"\" Initialize the dataset with dictl and df forms; initialize the mapping between categorical-int and string labels. - param raw_dictl: a list of dicts holding the raw data that DO NOT have annotation. - param train_dictl: a list of dicts holding the batch-annotated noisy train set. - param dev_dictl: a list of dicts holding the gold dev set. - param test_dictl: a list of dicts holding the gold test set. - param feature_key: key in each piece of dict mapping to the feature. - param label_key: key in each piece of dict mapping to the ground truth in STRING form. \"\"\" def dictl_transform ( dictl , labels = True ): \"\"\" Burner function to transform the input list of dictionaries into standard format. \"\"\" # transform the feature and possibly the label key_transform = { feature_key : self . __class__ . FEATURE_KEY } if labels : key_transform [ label_key ] = \"label\" # corner case when dictl is empty or None if not dictl : return [] return [ { key_transform . get ( _key , _key ): _value for _key , _value in _dict . items () } for _dict in dictl ] self . dictls = { \"raw\" : dictl_transform ( raw_dictl , labels = False ), \"train\" : dictl_transform ( train_dictl ), \"dev\" : dictl_transform ( dev_dictl ), \"test\" : dictl_transform ( test_dictl ), } self . synchronize_dictl_to_df () self . df_deduplicate () self . synchronize_df_to_dictl () self . setup_label_coding ()","title":"__init__()"},{"location":"reference/core-dataset/#hover.core.dataset.SupervisableDataset.compute_2d_embedding","text":"Get embeddings in the xy-plane and return the reducer. Source code in hover/core/dataset.py def compute_2d_embedding ( self , vectorizer , method , ** kwargs ): \"\"\" Get embeddings in the xy-plane and return the reducer. \"\"\" from hover.core.representation.reduction import DimensionalityReducer # prepare input vectors to manifold learning subset = [ \"raw\" , \"train\" , \"dev\" ] fit_inp = [] for _key in subset : _df = self . dfs [ _key ] if _df . empty : continue fit_inp += _df [ self . __class__ . FEATURE_KEY ] . tolist () fit_arr = np . array ([ vectorizer ( _inp ) for _inp in tqdm ( fit_inp )]) # initialize and fit manifold learning reducer reducer = DimensionalityReducer ( fit_arr ) embedding = reducer . fit_transform ( method , ** kwargs ) # assign x and y coordinates to dataset start_idx = 0 for _key in subset : _df = self . dfs [ _key ] _length = _df . shape [ 0 ] _df [ \"x\" ] = pd . Series ( embedding [ start_idx : ( start_idx + _length ), 0 ]) _df [ \"y\" ] = pd . Series ( embedding [ start_idx : ( start_idx + _length ), 1 ]) start_idx += _length return reducer","title":"compute_2d_embedding()"},{"location":"reference/core-dataset/#hover.core.dataset.SupervisableDataset.loader","text":"Prepare a Torch Dataloader for training or evaluation. param key(str): the subset of dataset to use. param vectorizer(callable): callable that turns a string into a vector. param smoothing_coeff: the smoothing coeffient for soft labels. type smoothing_coeff: float Source code in hover/core/dataset.py def loader ( self , key , vectorizer , batch_size = 64 , smoothing_coeff = 0.0 ): \"\"\" Prepare a Torch Dataloader for training or evaluation. - param key(str): the subset of dataset to use. - param vectorizer(callable): callable that turns a string into a vector. - param smoothing_coeff: the smoothing coeffient for soft labels. - type smoothing_coeff: float \"\"\" # take the slice that has a meaningful label df = self . dfs [ key ][ self . dfs [ key ][ \"label\" ] != module_config . ABSTAIN_DECODED ] labels = df [ \"label\" ] . apply ( lambda x : self . label_encoder [ x ]) . tolist () features = df [ self . __class__ . FEATURE_KEY ] . tolist () output_vectors = one_hot ( labels , num_classes = len ( self . classes )) console . print ( f \"Preparing { key } input vectors...\" , style = \"blue\" ) input_vectors = [ vectorizer ( _f ) for _f in tqdm ( features )] if smoothing_coeff > 0.0 : output_vectors = label_smoothing ( output_vectors , coefficient = smoothing_coeff ) console . print ( f \"Preparing { key } data loader...\" , style = \"blue\" ) loader = vector_dataloader ( input_vectors , output_vectors , batch_size = batch_size ) console . print ( f \"Prepared { key } loader consisting of { len ( features ) } examples with batch size { batch_size } \" , style = \"green\" , ) return loader","title":"loader()"},{"location":"reference/core-dataset/#hovercoredatasetsupervisabletextdataset","text":"","title":"hover.core.dataset.SupervisableTextDataset"},{"location":"reference/core-dataset/#hover.core.dataset.SupervisableTextDataset","text":"Can add text-specific methods.","title":"hover.core.dataset.SupervisableTextDataset"},{"location":"reference/core-explorer/","text":"hover.core.explorer.BokehForLabeledText Base class that keeps template explorer settings. Assumes: - in supplied dataframes - (always) text data in a 'text' column - (always) xy coordinates in 'x' and 'y' columns - (always) an index for the rows - (likely) classification label in a 'label' column Does not assume: - what the explorer serves to do. __init__ ( self , df_dict , ** kwargs ) special Operations shared by all child classes. (1) settle the figure settings by using child class defaults + kwargs overrides (2) settle the glyph settings by using child class defaults (3) create widgets that child classes can override (4) create data sources the correspond to class-specific data subsets. (5) activate builtin search callbacks depending on the child class. (6) create a (likely) blank figure under such settings Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" Operations shared by all child classes. (1) settle the figure settings by using child class defaults + kwargs overrides (2) settle the glyph settings by using child class defaults (3) create widgets that child classes can override (4) create data sources the correspond to class-specific data subsets. (5) activate builtin search callbacks depending on the child class. (6) create a (likely) blank figure under such settings \"\"\" logger . divider ( f \"Initializing { self . __class__ . __name__ } \" ) self . figure_kwargs = self . __class__ . DEFAULT_FIGURE_KWARGS . copy () self . figure_kwargs . update ( kwargs ) self . glyph_kwargs = { _key : _dict [ \"constant\" ] . copy () for _key , _dict in self . __class__ . DATA_KEY_TO_KWARGS . items () } self . _setup_widgets () self . _setup_dfs ( df_dict ) self . _setup_sources () self . _activate_search_builtin () self . figure = figure ( ** self . figure_kwargs ) self . reset_figure () _setup_sources ( self ) private Create (NOT UPDATE) ColumnDataSource objects. Intended to be extended in child classes for pre/post processing. Source code in hover/core/explorer.py def _setup_sources ( self ): \"\"\" Create (NOT UPDATE) ColumnDataSource objects. Intended to be extended in child classes for pre/post processing. \"\"\" logger . info ( \"Setting up sources\" ) self . sources = { _key : ColumnDataSource ( _df ) for _key , _df in self . dfs . items ()} _update_sources ( self ) private Update the sources with the corresponding dfs. Note that it seems mandatory to re-activate the search widgets. This is because the source loses plotting kwargs. Source code in hover/core/explorer.py def _update_sources ( self ): \"\"\" Update the sources with the corresponding dfs. Note that it seems mandatory to re-activate the search widgets. This is because the source loses plotting kwargs. \"\"\" for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): self . sources [ _key ] . data = self . dfs [ _key ] self . _activate_search_builtin () activate_search ( self , source , kwargs , altered_param = ( 'size' , 10 , 5 , 7 )) Enables string/regex search-and-highlight mechanism. Modifies the plotting source in-place. Source code in hover/core/explorer.py def activate_search ( self , source , kwargs , altered_param = ( \"size\" , 10 , 5 , 7 )): \"\"\" Enables string/regex search-and-highlight mechanism. Modifies the plotting source in-place. \"\"\" assert isinstance ( source , ColumnDataSource ) assert isinstance ( kwargs , dict ) updated_kwargs = kwargs . copy () param_key , param_pos , param_neg , param_default = altered_param num_points = len ( source . data [ \"text\" ]) default_param_list = [ param_default ] * num_points source . add ( default_param_list , f \" { param_key } \" ) updated_kwargs [ param_key ] = param_key search_callback = CustomJS ( args = { \"source\" : source , \"key_pos\" : self . search_pos , \"key_neg\" : self . search_neg , \"param_pos\" : param_pos , \"param_neg\" : param_neg , \"param_default\" : param_default , }, code = f \"\"\" const data = source.data; const text = data['text']; var arr = data[' { param_key } ']; \"\"\" + \"\"\" var search_pos = key_pos.value; var search_neg = key_neg.value; var valid_pos = (search_pos.length > 0); var valid_neg = (search_neg.length > 0); function determineAttr(candidate) { var score = 0; if (valid_pos) { if (candidate.search(search_pos) >= 0) { score += 1; } else { score -= 2; } }; if (valid_neg) { if (candidate.search(search_neg) < 0) { score += 1; } else { score -= 2; } }; if (score > 0) { return param_pos; } else if (score < 0) { return param_neg; } else {return param_default;} } function toRegex(search_key) { var match = search_key.match(new RegExp('^/(.*?)/([gimy]*)$')); if (match) { return new RegExp(match[1], match[2]); } else { return search_key; } } if (valid_pos) {search_pos = toRegex(search_pos);} if (valid_neg) {search_neg = toRegex(search_neg);} for (var i = 0; i < arr.length; i++) { arr[i] = determineAttr(text[i]); } source.change.emit() \"\"\" , ) self . search_pos . js_on_change ( \"value\" , search_callback ) self . search_neg . js_on_change ( \"value\" , search_callback ) return updated_kwargs link_selection ( self , key , other , other_key ) Sync the selected indices between specified sources. Source code in hover/core/explorer.py def link_selection ( self , key , other , other_key ): \"\"\" Sync the selected indices between specified sources. \"\"\" self . _prelink_check ( other ) # link selection in a bidirectional manner sl , sr = self . sources [ key ], other . sources [ other_key ] sl . selected . js_link ( \"indices\" , sr . selected , \"indices\" ) sr . selected . js_link ( \"indices\" , sl . selected , \"indices\" ) link_xy_range ( self , other ) Sync plotting ranges on the xy-plane. Source code in hover/core/explorer.py def link_xy_range ( self , other ): \"\"\" Sync plotting ranges on the xy-plane. \"\"\" self . _prelink_check ( other ) # link coordinate ranges in a bidirectional manner for _attr in [ \"start\" , \"end\" ]: self . figure . x_range . js_link ( _attr , other . figure . x_range , _attr ) self . figure . y_range . js_link ( _attr , other . figure . y_range , _attr ) other . figure . x_range . js_link ( _attr , self . figure . x_range , _attr ) other . figure . y_range . js_link ( _attr , self . figure . y_range , _attr ) reset_figure ( self ) Start over on the figure. Source code in hover/core/explorer.py def reset_figure ( self ): \"\"\"Start over on the figure.\"\"\" logger . info ( \"Resetting figure\" ) self . figure . renderers . clear () hover.core.explorer.BokehCorpusExplorer Plot unlabeled, 2D-vectorized text data points in a corpus. Features: - the search widgets will highlight the results through a change of color, which is arguably the best visual effect. __init__ ( self , df_dict , ** kwargs ) special Requires the input dataframe to contain: (1) \"x\" and \"y\" columns for coordinates; (2) a \"text\" column for data point tooltips. Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" Requires the input dataframe to contain: (1) \"x\" and \"y\" columns for coordinates; (2) a \"text\" column for data point tooltips. \"\"\" super () . __init__ ( df_dict , ** kwargs ) plot ( self , * args , ** kwargs ) (Re)-plot the corpus. Called just once per instance most of the time. Source code in hover/core/explorer.py def plot ( self , * args , ** kwargs ): \"\"\" (Re)-plot the corpus. Called just once per instance most of the time. \"\"\" self . figure . circle ( \"x\" , \"y\" , name = \"raw\" , source = self . sources [ \"raw\" ], ** self . glyph_kwargs [ \"raw\" ] ) hover.core.explorer.BokehCorpusAnnotator Annoate text data points via callbacks. Features: - alter values in the 'label' column through the widgets. - SERVER ONLY : only works in a setting that allows Python callbacks. __init__ ( self , df_dict , ** kwargs ) special Conceptually the same as the parent method. Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\"Conceptually the same as the parent method.\"\"\" super () . __init__ ( df_dict , ** kwargs ) plot ( self ) Re-plot with the new labels. Overrides the parent method. Determines the label->color mapping dynamically. Source code in hover/core/explorer.py def plot ( self ): \"\"\" Re-plot with the new labels. Overrides the parent method. Determines the label->color mapping dynamically. \"\"\" all_labels = sorted ( set ( self . dfs [ \"raw\" ][ \"label\" ] . values ), reverse = True ) cmap = auto_cmap ( all_labels ) self . figure . circle ( x = \"x\" , y = \"y\" , name = \"raw\" , color = factor_cmap ( \"label\" , cmap , all_labels ), legend_field = \"label\" , source = self . sources [ \"raw\" ], ** self . glyph_kwargs [ \"raw\" ], ) hover.core.explorer.BokehSoftLabelExplorer Plot text data points according to their labels and confidence scores. Features: - the predicted label will correspond to fill_color. - the confidence score, assumed to be a float between 0.0 and 1.0, will be reflected through fill_alpha. - currently not considering multi-label scenarios. __init__ ( self , df_dict , label_col , score_col , ** kwargs ) special On top of the requirements of the parent class, the input dataframe should contain: (1) label_col and score_col for \"soft predictions\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , label_col , score_col , ** kwargs ): \"\"\" On top of the requirements of the parent class, the input dataframe should contain: (1) label_col and score_col for \"soft predictions\". \"\"\" assert label_col != \"label\" , \"'label' field is reserved\" self . label_col = label_col self . score_col = score_col kwargs . update ( { \"tooltips\" : bokeh_hover_tooltip ( label = True , text = True , image = False , coords = True , index = True , custom = { \"Soft Label\" : self . label_col , \"Soft Score\" : self . score_col }, ) } ) super () . __init__ ( df_dict , ** kwargs ) plot ( self , ** kwargs ) Plot the confidence map. Source code in hover/core/explorer.py def plot ( self , ** kwargs ): \"\"\" Plot the confidence map. \"\"\" # auto-detect all labels all_labels = set () for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): _df = self . dfs [ _key ] _labels = set ( _df [ self . label_col ] . values ) all_labels = all_labels . union ( _labels ) all_labels = sorted ( all_labels , reverse = True ) cmap = auto_cmap ( all_labels ) for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): # prepare plot settings preset_kwargs = { \"legend_field\" : self . label_col , \"color\" : factor_cmap ( self . label_col , cmap , all_labels ), \"fill_alpha\" : self . score_col , } eff_kwargs = self . glyph_kwargs [ _key ] . copy () eff_kwargs . update ( preset_kwargs ) eff_kwargs . update ( kwargs ) self . figure . circle ( \"x\" , \"y\" , name = _key , source = self . sources [ _key ], ** eff_kwargs ) hover.core.explorer.BokehMarginExplorer Plot text data points along with two versions of labels. Could be useful for A/B tests. Features: - can choose to only plot the margins about specific labels. - currently not considering multi-label scenarios. __init__ ( self , df_dict , label_col_a , label_col_b , ** kwargs ) special On top of the requirements of the parent class, the input dataframe should contain: (1) label_col_a and label_col_b for \"label margins\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , label_col_a , label_col_b , ** kwargs ): \"\"\" On top of the requirements of the parent class, the input dataframe should contain: (1) label_col_a and label_col_b for \"label margins\". \"\"\" self . label_col_a = label_col_a self . label_col_b = label_col_b super () . __init__ ( df_dict , ** kwargs ) plot ( self , label , ** kwargs ) Plot the margins about a single label. Source code in hover/core/explorer.py def plot ( self , label , ** kwargs ): \"\"\" Plot the margins about a single label. \"\"\" # prepare plot settings axes = ( \"x\" , \"y\" ) eff_kwargs = self . glyph_kwargs [ \"raw\" ] . copy () eff_kwargs . update ( kwargs ) eff_kwargs [ \"legend_label\" ] = f \" { label } \" # create agreement/increment/decrement subsets col_a_pos = np . where ( self . dfs [ \"raw\" ][ self . label_col_a ] == label )[ 0 ] . tolist () col_a_neg = np . where ( self . dfs [ \"raw\" ][ self . label_col_a ] != label )[ 0 ] . tolist () col_b_pos = np . where ( self . dfs [ \"raw\" ][ self . label_col_b ] == label )[ 0 ] . tolist () col_b_neg = np . where ( self . dfs [ \"raw\" ][ self . label_col_b ] != label )[ 0 ] . tolist () agreement_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_pos ), IndexFilter ( col_b_pos )], ) increment_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_neg ), IndexFilter ( col_b_pos )], ) decrement_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_pos ), IndexFilter ( col_b_neg )], ) to_plot = [ { \"view\" : agreement_view , \"marker\" : self . figure . square }, { \"view\" : increment_view , \"marker\" : self . figure . x }, { \"view\" : decrement_view , \"marker\" : self . figure . cross }, ] # plot created subsets for _dict in to_plot : _view = _dict [ \"view\" ] _marker = _dict [ \"marker\" ] _marker ( * axes , name = \"raw\" , source = self . sources [ \"raw\" ], view = _view , ** eff_kwargs ) hover.core.explorer.BokehSnorkelExplorer Plot text data points along with labeling function (LF) outputs. Features: - each labeling function corresponds to its own line_color. - uses a different marker for each type of predictions: square for 'correct', x for 'incorrect', cross for 'missed', circle for 'hit'. - 'correct': the LF made a correct prediction on a point in the 'labeled' set. - 'incorrect': the LF made an incorrect prediction on a point in the 'labeled' set. - 'missed': the LF is capable of predicting the target class, but did not make such prediction on the particular point. - 'hit': the LF made a prediction on a point in the 'raw' set. __init__ ( self , df_dict , ** kwargs ) special On top of the requirements of the parent class, the df_labeled input dataframe should contain: (1) a \"label\" column for \"ground truths\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" On top of the requirements of the parent class, the df_labeled input dataframe should contain: (1) a \"label\" column for \"ground truths\". \"\"\" super () . __init__ ( df_dict , ** kwargs ) # initialize a list to keep track of plotted LFs self . lfs = [] self . palette = Category20 [ 20 ]","title":"hover.core.explorer"},{"location":"reference/core-explorer/#hovercoreexplorerbokehforlabeledtext","text":"","title":"hover.core.explorer.BokehForLabeledText"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText","text":"Base class that keeps template explorer settings. Assumes: - in supplied dataframes - (always) text data in a 'text' column - (always) xy coordinates in 'x' and 'y' columns - (always) an index for the rows - (likely) classification label in a 'label' column Does not assume: - what the explorer serves to do.","title":"hover.core.explorer.BokehForLabeledText"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText.__init__","text":"Operations shared by all child classes. (1) settle the figure settings by using child class defaults + kwargs overrides (2) settle the glyph settings by using child class defaults (3) create widgets that child classes can override (4) create data sources the correspond to class-specific data subsets. (5) activate builtin search callbacks depending on the child class. (6) create a (likely) blank figure under such settings Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" Operations shared by all child classes. (1) settle the figure settings by using child class defaults + kwargs overrides (2) settle the glyph settings by using child class defaults (3) create widgets that child classes can override (4) create data sources the correspond to class-specific data subsets. (5) activate builtin search callbacks depending on the child class. (6) create a (likely) blank figure under such settings \"\"\" logger . divider ( f \"Initializing { self . __class__ . __name__ } \" ) self . figure_kwargs = self . __class__ . DEFAULT_FIGURE_KWARGS . copy () self . figure_kwargs . update ( kwargs ) self . glyph_kwargs = { _key : _dict [ \"constant\" ] . copy () for _key , _dict in self . __class__ . DATA_KEY_TO_KWARGS . items () } self . _setup_widgets () self . _setup_dfs ( df_dict ) self . _setup_sources () self . _activate_search_builtin () self . figure = figure ( ** self . figure_kwargs ) self . reset_figure ()","title":"__init__()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText._setup_sources","text":"Create (NOT UPDATE) ColumnDataSource objects. Intended to be extended in child classes for pre/post processing. Source code in hover/core/explorer.py def _setup_sources ( self ): \"\"\" Create (NOT UPDATE) ColumnDataSource objects. Intended to be extended in child classes for pre/post processing. \"\"\" logger . info ( \"Setting up sources\" ) self . sources = { _key : ColumnDataSource ( _df ) for _key , _df in self . dfs . items ()}","title":"_setup_sources()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText._update_sources","text":"Update the sources with the corresponding dfs. Note that it seems mandatory to re-activate the search widgets. This is because the source loses plotting kwargs. Source code in hover/core/explorer.py def _update_sources ( self ): \"\"\" Update the sources with the corresponding dfs. Note that it seems mandatory to re-activate the search widgets. This is because the source loses plotting kwargs. \"\"\" for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): self . sources [ _key ] . data = self . dfs [ _key ] self . _activate_search_builtin ()","title":"_update_sources()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText.activate_search","text":"Enables string/regex search-and-highlight mechanism. Modifies the plotting source in-place. Source code in hover/core/explorer.py def activate_search ( self , source , kwargs , altered_param = ( \"size\" , 10 , 5 , 7 )): \"\"\" Enables string/regex search-and-highlight mechanism. Modifies the plotting source in-place. \"\"\" assert isinstance ( source , ColumnDataSource ) assert isinstance ( kwargs , dict ) updated_kwargs = kwargs . copy () param_key , param_pos , param_neg , param_default = altered_param num_points = len ( source . data [ \"text\" ]) default_param_list = [ param_default ] * num_points source . add ( default_param_list , f \" { param_key } \" ) updated_kwargs [ param_key ] = param_key search_callback = CustomJS ( args = { \"source\" : source , \"key_pos\" : self . search_pos , \"key_neg\" : self . search_neg , \"param_pos\" : param_pos , \"param_neg\" : param_neg , \"param_default\" : param_default , }, code = f \"\"\" const data = source.data; const text = data['text']; var arr = data[' { param_key } ']; \"\"\" + \"\"\" var search_pos = key_pos.value; var search_neg = key_neg.value; var valid_pos = (search_pos.length > 0); var valid_neg = (search_neg.length > 0); function determineAttr(candidate) { var score = 0; if (valid_pos) { if (candidate.search(search_pos) >= 0) { score += 1; } else { score -= 2; } }; if (valid_neg) { if (candidate.search(search_neg) < 0) { score += 1; } else { score -= 2; } }; if (score > 0) { return param_pos; } else if (score < 0) { return param_neg; } else {return param_default;} } function toRegex(search_key) { var match = search_key.match(new RegExp('^/(.*?)/([gimy]*)$')); if (match) { return new RegExp(match[1], match[2]); } else { return search_key; } } if (valid_pos) {search_pos = toRegex(search_pos);} if (valid_neg) {search_neg = toRegex(search_neg);} for (var i = 0; i < arr.length; i++) { arr[i] = determineAttr(text[i]); } source.change.emit() \"\"\" , ) self . search_pos . js_on_change ( \"value\" , search_callback ) self . search_neg . js_on_change ( \"value\" , search_callback ) return updated_kwargs","title":"activate_search()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText.link_selection","text":"Sync the selected indices between specified sources. Source code in hover/core/explorer.py def link_selection ( self , key , other , other_key ): \"\"\" Sync the selected indices between specified sources. \"\"\" self . _prelink_check ( other ) # link selection in a bidirectional manner sl , sr = self . sources [ key ], other . sources [ other_key ] sl . selected . js_link ( \"indices\" , sr . selected , \"indices\" ) sr . selected . js_link ( \"indices\" , sl . selected , \"indices\" )","title":"link_selection()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText.link_xy_range","text":"Sync plotting ranges on the xy-plane. Source code in hover/core/explorer.py def link_xy_range ( self , other ): \"\"\" Sync plotting ranges on the xy-plane. \"\"\" self . _prelink_check ( other ) # link coordinate ranges in a bidirectional manner for _attr in [ \"start\" , \"end\" ]: self . figure . x_range . js_link ( _attr , other . figure . x_range , _attr ) self . figure . y_range . js_link ( _attr , other . figure . y_range , _attr ) other . figure . x_range . js_link ( _attr , self . figure . x_range , _attr ) other . figure . y_range . js_link ( _attr , self . figure . y_range , _attr )","title":"link_xy_range()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehForLabeledText.reset_figure","text":"Start over on the figure. Source code in hover/core/explorer.py def reset_figure ( self ): \"\"\"Start over on the figure.\"\"\" logger . info ( \"Resetting figure\" ) self . figure . renderers . clear ()","title":"reset_figure()"},{"location":"reference/core-explorer/#hovercoreexplorerbokehcorpusexplorer","text":"","title":"hover.core.explorer.BokehCorpusExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusExplorer","text":"Plot unlabeled, 2D-vectorized text data points in a corpus. Features: - the search widgets will highlight the results through a change of color, which is arguably the best visual effect.","title":"hover.core.explorer.BokehCorpusExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusExplorer.__init__","text":"Requires the input dataframe to contain: (1) \"x\" and \"y\" columns for coordinates; (2) a \"text\" column for data point tooltips. Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" Requires the input dataframe to contain: (1) \"x\" and \"y\" columns for coordinates; (2) a \"text\" column for data point tooltips. \"\"\" super () . __init__ ( df_dict , ** kwargs )","title":"__init__()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusExplorer.plot","text":"(Re)-plot the corpus. Called just once per instance most of the time. Source code in hover/core/explorer.py def plot ( self , * args , ** kwargs ): \"\"\" (Re)-plot the corpus. Called just once per instance most of the time. \"\"\" self . figure . circle ( \"x\" , \"y\" , name = \"raw\" , source = self . sources [ \"raw\" ], ** self . glyph_kwargs [ \"raw\" ] )","title":"plot()"},{"location":"reference/core-explorer/#hovercoreexplorerbokehcorpusannotator","text":"","title":"hover.core.explorer.BokehCorpusAnnotator"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusAnnotator","text":"Annoate text data points via callbacks. Features: - alter values in the 'label' column through the widgets. - SERVER ONLY : only works in a setting that allows Python callbacks.","title":"hover.core.explorer.BokehCorpusAnnotator"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusAnnotator.__init__","text":"Conceptually the same as the parent method. Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\"Conceptually the same as the parent method.\"\"\" super () . __init__ ( df_dict , ** kwargs )","title":"__init__()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehCorpusAnnotator.plot","text":"Re-plot with the new labels. Overrides the parent method. Determines the label->color mapping dynamically. Source code in hover/core/explorer.py def plot ( self ): \"\"\" Re-plot with the new labels. Overrides the parent method. Determines the label->color mapping dynamically. \"\"\" all_labels = sorted ( set ( self . dfs [ \"raw\" ][ \"label\" ] . values ), reverse = True ) cmap = auto_cmap ( all_labels ) self . figure . circle ( x = \"x\" , y = \"y\" , name = \"raw\" , color = factor_cmap ( \"label\" , cmap , all_labels ), legend_field = \"label\" , source = self . sources [ \"raw\" ], ** self . glyph_kwargs [ \"raw\" ], )","title":"plot()"},{"location":"reference/core-explorer/#hovercoreexplorerbokehsoftlabelexplorer","text":"","title":"hover.core.explorer.BokehSoftLabelExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehSoftLabelExplorer","text":"Plot text data points according to their labels and confidence scores. Features: - the predicted label will correspond to fill_color. - the confidence score, assumed to be a float between 0.0 and 1.0, will be reflected through fill_alpha. - currently not considering multi-label scenarios.","title":"hover.core.explorer.BokehSoftLabelExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehSoftLabelExplorer.__init__","text":"On top of the requirements of the parent class, the input dataframe should contain: (1) label_col and score_col for \"soft predictions\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , label_col , score_col , ** kwargs ): \"\"\" On top of the requirements of the parent class, the input dataframe should contain: (1) label_col and score_col for \"soft predictions\". \"\"\" assert label_col != \"label\" , \"'label' field is reserved\" self . label_col = label_col self . score_col = score_col kwargs . update ( { \"tooltips\" : bokeh_hover_tooltip ( label = True , text = True , image = False , coords = True , index = True , custom = { \"Soft Label\" : self . label_col , \"Soft Score\" : self . score_col }, ) } ) super () . __init__ ( df_dict , ** kwargs )","title":"__init__()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehSoftLabelExplorer.plot","text":"Plot the confidence map. Source code in hover/core/explorer.py def plot ( self , ** kwargs ): \"\"\" Plot the confidence map. \"\"\" # auto-detect all labels all_labels = set () for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): _df = self . dfs [ _key ] _labels = set ( _df [ self . label_col ] . values ) all_labels = all_labels . union ( _labels ) all_labels = sorted ( all_labels , reverse = True ) cmap = auto_cmap ( all_labels ) for _key in self . __class__ . DATA_KEY_TO_KWARGS . keys (): # prepare plot settings preset_kwargs = { \"legend_field\" : self . label_col , \"color\" : factor_cmap ( self . label_col , cmap , all_labels ), \"fill_alpha\" : self . score_col , } eff_kwargs = self . glyph_kwargs [ _key ] . copy () eff_kwargs . update ( preset_kwargs ) eff_kwargs . update ( kwargs ) self . figure . circle ( \"x\" , \"y\" , name = _key , source = self . sources [ _key ], ** eff_kwargs )","title":"plot()"},{"location":"reference/core-explorer/#hovercoreexplorerbokehmarginexplorer","text":"","title":"hover.core.explorer.BokehMarginExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehMarginExplorer","text":"Plot text data points along with two versions of labels. Could be useful for A/B tests. Features: - can choose to only plot the margins about specific labels. - currently not considering multi-label scenarios.","title":"hover.core.explorer.BokehMarginExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehMarginExplorer.__init__","text":"On top of the requirements of the parent class, the input dataframe should contain: (1) label_col_a and label_col_b for \"label margins\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , label_col_a , label_col_b , ** kwargs ): \"\"\" On top of the requirements of the parent class, the input dataframe should contain: (1) label_col_a and label_col_b for \"label margins\". \"\"\" self . label_col_a = label_col_a self . label_col_b = label_col_b super () . __init__ ( df_dict , ** kwargs )","title":"__init__()"},{"location":"reference/core-explorer/#hover.core.explorer.BokehMarginExplorer.plot","text":"Plot the margins about a single label. Source code in hover/core/explorer.py def plot ( self , label , ** kwargs ): \"\"\" Plot the margins about a single label. \"\"\" # prepare plot settings axes = ( \"x\" , \"y\" ) eff_kwargs = self . glyph_kwargs [ \"raw\" ] . copy () eff_kwargs . update ( kwargs ) eff_kwargs [ \"legend_label\" ] = f \" { label } \" # create agreement/increment/decrement subsets col_a_pos = np . where ( self . dfs [ \"raw\" ][ self . label_col_a ] == label )[ 0 ] . tolist () col_a_neg = np . where ( self . dfs [ \"raw\" ][ self . label_col_a ] != label )[ 0 ] . tolist () col_b_pos = np . where ( self . dfs [ \"raw\" ][ self . label_col_b ] == label )[ 0 ] . tolist () col_b_neg = np . where ( self . dfs [ \"raw\" ][ self . label_col_b ] != label )[ 0 ] . tolist () agreement_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_pos ), IndexFilter ( col_b_pos )], ) increment_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_neg ), IndexFilter ( col_b_pos )], ) decrement_view = CDSView ( source = self . sources [ \"raw\" ], filters = [ IndexFilter ( col_a_pos ), IndexFilter ( col_b_neg )], ) to_plot = [ { \"view\" : agreement_view , \"marker\" : self . figure . square }, { \"view\" : increment_view , \"marker\" : self . figure . x }, { \"view\" : decrement_view , \"marker\" : self . figure . cross }, ] # plot created subsets for _dict in to_plot : _view = _dict [ \"view\" ] _marker = _dict [ \"marker\" ] _marker ( * axes , name = \"raw\" , source = self . sources [ \"raw\" ], view = _view , ** eff_kwargs )","title":"plot()"},{"location":"reference/core-explorer/#hovercoreexplorerbokehsnorkelexplorer","text":"","title":"hover.core.explorer.BokehSnorkelExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehSnorkelExplorer","text":"Plot text data points along with labeling function (LF) outputs. Features: - each labeling function corresponds to its own line_color. - uses a different marker for each type of predictions: square for 'correct', x for 'incorrect', cross for 'missed', circle for 'hit'. - 'correct': the LF made a correct prediction on a point in the 'labeled' set. - 'incorrect': the LF made an incorrect prediction on a point in the 'labeled' set. - 'missed': the LF is capable of predicting the target class, but did not make such prediction on the particular point. - 'hit': the LF made a prediction on a point in the 'raw' set.","title":"hover.core.explorer.BokehSnorkelExplorer"},{"location":"reference/core-explorer/#hover.core.explorer.BokehSnorkelExplorer.__init__","text":"On top of the requirements of the parent class, the df_labeled input dataframe should contain: (1) a \"label\" column for \"ground truths\". Source code in hover/core/explorer.py def __init__ ( self , df_dict , ** kwargs ): \"\"\" On top of the requirements of the parent class, the df_labeled input dataframe should contain: (1) a \"label\" column for \"ground truths\". \"\"\" super () . __init__ ( df_dict , ** kwargs ) # initialize a list to keep track of plotted LFs self . lfs = [] self . palette = Category20 [ 20 ]","title":"__init__()"},{"location":"reference/core-neural/","text":"hover.core.neural.VectorNet Simple transfer learning model: a user-supplied vectorizer followed by a neural net. This is a parent class whose children may use different training schemes. Please refer to hover.utils.torch_helper.VectorDataset and vector_dataloader for more info. __init__ ( self , vectorizer , architecture , state_dict_path , labels ) special param vectorizer(callable): a function that converts any string to a NumPy 1-D array. param architecture(class): a torch.nn.Module child class to be instantiated into a neural net. param state_dict_path(str): path to a PyTorch state dict that matches the architecture. param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. Source code in hover/core/neural.py def __init__ ( self , vectorizer , architecture , state_dict_path , labels ): \"\"\" - param vectorizer(callable): a function that converts any string to a NumPy 1-D array. - param architecture(class): a `torch.nn.Module` child class to be instantiated into a neural net. - param state_dict_path(str): path to a PyTorch state dict that matches the architecture. - param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. \"\"\" # set up label conversion self . label_encoder = { _label : i for i , _label in enumerate ( labels )} self . label_decoder = { i : _label for i , _label in enumerate ( labels )} self . num_classes = len ( self . label_encoder ) # set up vectorizer and the neural network with appropriate dimensions self . vectorizer = vectorizer vec_dim = self . vectorizer ( \"\" ) . shape [ 0 ] self . nn = architecture ( vec_dim , self . num_classes ) # if a state dict exists, load it and create a backup copy import os if os . path . isfile ( state_dict_path ): from shutil import copyfile try : self . nn . load_state_dict ( torch . load ( state_dict_path )) except Exception as e : logger . warn ( f \"Load VectorNet state path failed with { type ( e ) } : e\" ) state_dict_backup_path = ( f \" { state_dict_path } . { datetime . now () . strftime ( '%Y%m %d %H%M%S' ) } \" ) copyfile ( state_dict_path , state_dict_backup_path ) # set a path to store updated parameters self . nn_update_path = state_dict_path # initialize an optimizer object and a dict to hold dynamic parameters self . nn_optimizer = torch . optim . Adam ( self . nn . parameters ()) self . _dynamic_params = { \"optimizer\" : { \"lr\" : 0.01 , \"betas\" : ( 0.9 , 0.999 )}} evaluate ( self , dev_loader , verbose = 1 ) Evaluate the neural network against a dev set. Source code in hover/core/neural.py def evaluate ( self , dev_loader , verbose = 1 ): \"\"\" Evaluate the neural network against a dev set. \"\"\" self . nn . eval () true = [] pred = [] for loaded_input , loaded_output , _idx in dev_loader : _input_tensor = loaded_input . float () _output_tensor = loaded_output . float () _logits = self . nn ( _input_tensor ) _true_batch = _output_tensor . argmax ( dim = 1 ) . detach () . numpy () _pred_batch = F . softmax ( _logits , dim = 1 ) . argmax ( dim = 1 ) . detach () . numpy () true . append ( _true_batch ) pred . append ( _pred_batch ) true = np . concatenate ( true ) pred = np . concatenate ( pred ) accuracy = classification_accuracy ( true , pred ) conf_mat = confusion_matrix ( true , pred ) if verbose > 0 : log_info = dict ( self . _dynamic_params ) log_info [ \"performance\" ] = \"Acc {0:.3f} \" . format ( accuracy ) logger . info ( \" {0: <80} \" . format ( \"Eval: Epoch {epoch} {performance} \" . format ( ** log_info ) ) ) return accuracy , conf_mat predict_proba ( self , inps ) End-to-end single/multi-piece prediction from inp to class probabilities. Source code in hover/core/neural.py def predict_proba ( self , inps ): \"\"\" End-to-end single/multi-piece prediction from inp to class probabilities. \"\"\" # if the input is a single piece of inp, cast it to a list FLAG_SINGLE = isinstance ( inps , str ) if FLAG_SINGLE : inps = [ inps ] # the actual prediction self . nn . eval () vectors = torch . Tensor ([ self . vectorizer ( _inp ) for _inp in inps ]) logits = self . nn ( vectors ) probs = F . softmax ( logits , dim =- 1 ) . detach () . numpy () # inverse-cast if applicable if FLAG_SINGLE : probs = probs [ 0 ] return probs save ( self , save_path = None ) Save the current state dict with authorization to overwrite. Source code in hover/core/neural.py def save ( self , save_path = None ): \"\"\" Save the current state dict with authorization to overwrite. \"\"\" if save_path is None : save_path = self . nn_update_path torch . save ( self . nn . state_dict (), save_path ) train ( self , train_loader , dev_loader = None , epochs = 1 , verbose = 1 ) Train the neural network. This method is a vanilla template and is intended to be overridden in child classes. Also intended to be coupled with self.train_batch(). Source code in hover/core/neural.py def train ( self , train_loader , dev_loader = None , epochs = 1 , verbose = 1 ): \"\"\" Train the neural network. - This method is a vanilla template and is intended to be overridden in child classes. - Also intended to be coupled with self.train_batch(). \"\"\" train_info = [] for epoch_idx in range ( epochs ): self . _dynamic_params [ \"epoch\" ] = epoch_idx + 1 self . train_epoch ( train_loader , verbose = verbose ) if dev_loader is not None : acc , conf_mat = self . evaluate ( dev_loader , verbose = verbose ) train_info . append ({ \"accuracy\" : acc , \"confusion_matrix\" : conf_mat }) return train_info train_batch ( self , loaded_input , loaded_output , verbose = 1 ) Train the neural network for one batch. Source code in hover/core/neural.py def train_batch ( self , loaded_input , loaded_output , verbose = 1 ): \"\"\" Train the neural network for one batch. \"\"\" self . nn . train () input_tensor = loaded_input . float () output_tensor = loaded_output . float () # compute logits logits = self . nn ( input_tensor ) loss = cross_entropy_with_probs ( logits , output_tensor ) self . nn_optimizer . zero_grad () loss . backward () self . nn_optimizer . step () if verbose > 0 : log_info = dict ( self . _dynamic_params ) log_info [ \"performance\" ] = \"Loss {0:.3f} \" . format ( loss ) print ( \" {0: <80} \" . format ( \"Train: Epoch {epoch} Batch {batch} {performance} \" . format ( ** log_info ) ), end = \" \\r \" , ) train_epoch ( self , train_loader , * args , ** kwargs ) Train the neural network for one epoch. Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently. Source code in hover/core/neural.py def train_epoch ( self , train_loader , * args , ** kwargs ): \"\"\" Train the neural network for one epoch. - Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently. \"\"\" self . adjust_optimizer_params () for batch_idx , ( loaded_input , loaded_output , _ ) in enumerate ( train_loader ): self . _dynamic_params [ \"batch\" ] = batch_idx + 1 self . train_batch ( loaded_input , loaded_output , * args , ** kwargs ) hover.core.neural.create_vector_net_from_module Create a TextVectorNet model, or of its child class. param specific_class(class): TextVectorNet or its child class. param model_module_name(str): path to a local Python module in the working directory whose init .py file contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable. param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. Source code in hover/core/neural.py def create_vector_net_from_module ( specific_class , model_module_name , labels ): \"\"\" Create a TextVectorNet model, or of its child class. - param specific_class(class): TextVectorNet or its child class. - param model_module_name(str): path to a local Python module in the working directory whose __init__.py file contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable. - param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. \"\"\" from importlib import import_module model_module = import_module ( model_module_name ) # Load the model by retrieving the inp-to-vec function, architecture, and state dict model = specific_class ( model_module . get_vectorizer (), model_module . get_architecture (), model_module . get_state_dict_path (), labels , ) return model","title":"hover.core.neural"},{"location":"reference/core-neural/#hovercoreneuralvectornet","text":"","title":"hover.core.neural.VectorNet"},{"location":"reference/core-neural/#hover.core.neural.VectorNet","text":"Simple transfer learning model: a user-supplied vectorizer followed by a neural net. This is a parent class whose children may use different training schemes. Please refer to hover.utils.torch_helper.VectorDataset and vector_dataloader for more info.","title":"hover.core.neural.VectorNet"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.__init__","text":"param vectorizer(callable): a function that converts any string to a NumPy 1-D array. param architecture(class): a torch.nn.Module child class to be instantiated into a neural net. param state_dict_path(str): path to a PyTorch state dict that matches the architecture. param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. Source code in hover/core/neural.py def __init__ ( self , vectorizer , architecture , state_dict_path , labels ): \"\"\" - param vectorizer(callable): a function that converts any string to a NumPy 1-D array. - param architecture(class): a `torch.nn.Module` child class to be instantiated into a neural net. - param state_dict_path(str): path to a PyTorch state dict that matches the architecture. - param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. \"\"\" # set up label conversion self . label_encoder = { _label : i for i , _label in enumerate ( labels )} self . label_decoder = { i : _label for i , _label in enumerate ( labels )} self . num_classes = len ( self . label_encoder ) # set up vectorizer and the neural network with appropriate dimensions self . vectorizer = vectorizer vec_dim = self . vectorizer ( \"\" ) . shape [ 0 ] self . nn = architecture ( vec_dim , self . num_classes ) # if a state dict exists, load it and create a backup copy import os if os . path . isfile ( state_dict_path ): from shutil import copyfile try : self . nn . load_state_dict ( torch . load ( state_dict_path )) except Exception as e : logger . warn ( f \"Load VectorNet state path failed with { type ( e ) } : e\" ) state_dict_backup_path = ( f \" { state_dict_path } . { datetime . now () . strftime ( '%Y%m %d %H%M%S' ) } \" ) copyfile ( state_dict_path , state_dict_backup_path ) # set a path to store updated parameters self . nn_update_path = state_dict_path # initialize an optimizer object and a dict to hold dynamic parameters self . nn_optimizer = torch . optim . Adam ( self . nn . parameters ()) self . _dynamic_params = { \"optimizer\" : { \"lr\" : 0.01 , \"betas\" : ( 0.9 , 0.999 )}}","title":"__init__()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.evaluate","text":"Evaluate the neural network against a dev set. Source code in hover/core/neural.py def evaluate ( self , dev_loader , verbose = 1 ): \"\"\" Evaluate the neural network against a dev set. \"\"\" self . nn . eval () true = [] pred = [] for loaded_input , loaded_output , _idx in dev_loader : _input_tensor = loaded_input . float () _output_tensor = loaded_output . float () _logits = self . nn ( _input_tensor ) _true_batch = _output_tensor . argmax ( dim = 1 ) . detach () . numpy () _pred_batch = F . softmax ( _logits , dim = 1 ) . argmax ( dim = 1 ) . detach () . numpy () true . append ( _true_batch ) pred . append ( _pred_batch ) true = np . concatenate ( true ) pred = np . concatenate ( pred ) accuracy = classification_accuracy ( true , pred ) conf_mat = confusion_matrix ( true , pred ) if verbose > 0 : log_info = dict ( self . _dynamic_params ) log_info [ \"performance\" ] = \"Acc {0:.3f} \" . format ( accuracy ) logger . info ( \" {0: <80} \" . format ( \"Eval: Epoch {epoch} {performance} \" . format ( ** log_info ) ) ) return accuracy , conf_mat","title":"evaluate()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.predict_proba","text":"End-to-end single/multi-piece prediction from inp to class probabilities. Source code in hover/core/neural.py def predict_proba ( self , inps ): \"\"\" End-to-end single/multi-piece prediction from inp to class probabilities. \"\"\" # if the input is a single piece of inp, cast it to a list FLAG_SINGLE = isinstance ( inps , str ) if FLAG_SINGLE : inps = [ inps ] # the actual prediction self . nn . eval () vectors = torch . Tensor ([ self . vectorizer ( _inp ) for _inp in inps ]) logits = self . nn ( vectors ) probs = F . softmax ( logits , dim =- 1 ) . detach () . numpy () # inverse-cast if applicable if FLAG_SINGLE : probs = probs [ 0 ] return probs","title":"predict_proba()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.save","text":"Save the current state dict with authorization to overwrite. Source code in hover/core/neural.py def save ( self , save_path = None ): \"\"\" Save the current state dict with authorization to overwrite. \"\"\" if save_path is None : save_path = self . nn_update_path torch . save ( self . nn . state_dict (), save_path )","title":"save()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.train","text":"Train the neural network. This method is a vanilla template and is intended to be overridden in child classes. Also intended to be coupled with self.train_batch(). Source code in hover/core/neural.py def train ( self , train_loader , dev_loader = None , epochs = 1 , verbose = 1 ): \"\"\" Train the neural network. - This method is a vanilla template and is intended to be overridden in child classes. - Also intended to be coupled with self.train_batch(). \"\"\" train_info = [] for epoch_idx in range ( epochs ): self . _dynamic_params [ \"epoch\" ] = epoch_idx + 1 self . train_epoch ( train_loader , verbose = verbose ) if dev_loader is not None : acc , conf_mat = self . evaluate ( dev_loader , verbose = verbose ) train_info . append ({ \"accuracy\" : acc , \"confusion_matrix\" : conf_mat }) return train_info","title":"train()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.train_batch","text":"Train the neural network for one batch. Source code in hover/core/neural.py def train_batch ( self , loaded_input , loaded_output , verbose = 1 ): \"\"\" Train the neural network for one batch. \"\"\" self . nn . train () input_tensor = loaded_input . float () output_tensor = loaded_output . float () # compute logits logits = self . nn ( input_tensor ) loss = cross_entropy_with_probs ( logits , output_tensor ) self . nn_optimizer . zero_grad () loss . backward () self . nn_optimizer . step () if verbose > 0 : log_info = dict ( self . _dynamic_params ) log_info [ \"performance\" ] = \"Loss {0:.3f} \" . format ( loss ) print ( \" {0: <80} \" . format ( \"Train: Epoch {epoch} Batch {batch} {performance} \" . format ( ** log_info ) ), end = \" \\r \" , )","title":"train_batch()"},{"location":"reference/core-neural/#hover.core.neural.VectorNet.train_epoch","text":"Train the neural network for one epoch. Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently. Source code in hover/core/neural.py def train_epoch ( self , train_loader , * args , ** kwargs ): \"\"\" Train the neural network for one epoch. - Supports flexible args and kwargs for child classes that may implement self.train() and self.train_batch() differently. \"\"\" self . adjust_optimizer_params () for batch_idx , ( loaded_input , loaded_output , _ ) in enumerate ( train_loader ): self . _dynamic_params [ \"batch\" ] = batch_idx + 1 self . train_batch ( loaded_input , loaded_output , * args , ** kwargs )","title":"train_epoch()"},{"location":"reference/core-neural/#hovercoreneuralcreate_vector_net_from_module","text":"","title":"hover.core.neural.create_vector_net_from_module"},{"location":"reference/core-neural/#hover.core.neural.create_vector_net_from_module","text":"Create a TextVectorNet model, or of its child class. param specific_class(class): TextVectorNet or its child class. param model_module_name(str): path to a local Python module in the working directory whose init .py file contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable. param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. Source code in hover/core/neural.py def create_vector_net_from_module ( specific_class , model_module_name , labels ): \"\"\" Create a TextVectorNet model, or of its child class. - param specific_class(class): TextVectorNet or its child class. - param model_module_name(str): path to a local Python module in the working directory whose __init__.py file contains a get_vectorizer() callable, get_architecture() callable, and a get_state_dict_path() callable. - param labels(list of str): the classification labels, e.g. [\"POSITIVE\", \"NEGATIVE\"]. \"\"\" from importlib import import_module model_module = import_module ( model_module_name ) # Load the model by retrieving the inp-to-vec function, architecture, and state dict model = specific_class ( model_module . get_vectorizer (), model_module . get_architecture (), model_module . get_state_dict_path (), labels , ) return model","title":"hover.core.neural.create_vector_net_from_module"}]}